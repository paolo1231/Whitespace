# OpenAI Configuration
quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
# Using GPT-4 Turbo for better performance and lower latency
quarkus.langchain4j.openai.chat-model.model-name=${OPENAI_MODEL:gpt-4-turbo-preview}
quarkus.langchain4j.openai.chat-model.temperature=0.3
quarkus.langchain4j.openai.chat-model.max-tokens=2000
# Correct Timeout Configuration (60 seconds for complex code analysis)
quarkus.langchain4j.openai.timeout=60s
# HTTP Client Timeouts - Correct property names
quarkus.rest-client."io.quarkiverse.langchain4j.openai.runtime.OpenAiRestApi".connect-timeout=15000
quarkus.rest-client."io.quarkiverse.langchain4j.openai.runtime.OpenAiRestApi".read-timeout=60000
# Retry Configuration
quarkus.langchain4j.openai.max-retries=2
# HTTP Configuration
quarkus.http.port=${PORT:8080}
quarkus.http.host=0.0.0.0
quarkus.http.cors=true
quarkus.http.cors.origins=*
# HTTP Request Timeout (for frontend requests)
quarkus.http.read-timeout=90s
quarkus.http.idle-timeout=120s
# Cloud Configuration
quarkus.native.container-build=true
# Logging
quarkus.log.level=INFO
quarkus.log.category."com.whtspc".level=INFO
# Console Configuration (fixes NullPointerException in dev mode)
quarkus.console.enabled=false
quarkus.live-reload.instrumentation=false
# Debug Configuration
%dev.quarkus.log.level=DEBUG
%dev.quarkus.log.category."com.whtspc".level=DEBUG
%dev.quarkus.log.category."io.quarkus.langchain4j".level=DEBUG
# OpenAI Configuration
quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
# Using GPT-4 Turbo for better performance and lower latency
quarkus.langchain4j.openai.chat-model.model-name=${OPENAI_MODEL:gpt-4-turbo-preview}
quarkus.langchain4j.openai.chat-model.temperature=0.3
quarkus.langchain4j.openai.chat-model.max-tokens=2000

# Timeout Configuration (1 minute for complex code analysis)
quarkus.langchain4j.timeout=1m

# HTTP Client Timeouts
quarkus.rest-client.openai.connect-timeout=10000
quarkus.rest-client.openai.read-timeout=30000

# Retry Configuration
quarkus.langchain4j.openai.max-retries=3

# HTTP Configuration
quarkus.http.port=${PORT:8080}
quarkus.http.host=0.0.0.0
quarkus.http.cors=true
quarkus.http.cors.origins=*

# Cloud Configuration
quarkus.native.container-build=true

# Logging
quarkus.log.level=INFO
quarkus.log.category."com.whtspc".level=INFO

# Console Configuration (fixes NullPointerException in dev mode)
quarkus.console.enabled=false
quarkus.live-reload.instrumentation=false
quarkus.dev-ui.enabled=false

# Debug Configuration
%dev.quarkus.log.level=DEBUG
%dev.quarkus.log.category."com.whtspc".level=DEBUG
%dev.quarkus.log.category."io.quarkus.langchain4j".level=DEBUG
# OpenAI Configuration
quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
# Using GPT-5 Nano for better performance and lower latency
quarkus.langchain4j.openai.chat-model.model-name=${OPENAI_MODEL:gpt-4o-mini}
quarkus.langchain4j.openai.chat-model.temperature=0.3
quarkus.langchain4j.openai.chat-model.max-tokens=2000
# Grok Configuration (xAI)
grok.api-key=${GROK_API_KEY:}
# HTTP Configuration
quarkus.http.port=${PORT:8080}
quarkus.http.host=0.0.0.0
quarkus.http.cors=true
quarkus.http.cors.origins=*
# Cloud Configuration
quarkus.native.container-build=true
# Logging
quarkus.log.level=INFO
quarkus.log.category."com.whtspc".level=INFO
# Debug Configuration
%dev.quarkus.log.level=DEBUG
%dev.quarkus.log.category."com.whtspc".level=DEBUG
%dev.quarkus.log.category."io.quarkus.langchain4j".level=DEBUG
# Disable LangChain4j DevUI if causing issues
quarkus.langchain4j.devui.enabled=false